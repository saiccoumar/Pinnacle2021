{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000.0\n",
      "(100000, 4)\n",
      "(90000, 4)\n",
      "(10000, 4)\n",
      "Total Unique Users 943\n",
      "Total Unique Movies 1682\n",
      "  userId movieId  rating  timestamp\n",
      "0    196     242       3  881250949\n",
      "1    186     302       3  891717742\n",
      "2     22     377       1  878887116\n",
      "3    244      51       2  880606923\n",
      "4    166     346       1  886397596\n",
      "TRAIN\n",
      "(943, 1663)\n",
      "movieId  1  10  100  1000  1001  1002  1003  1004  1005  1006  ...  990  991  \\\n",
      "userId                                                         ...             \n",
      "1        5   3    5     0     0     0     0     0     0     0  ...    0    0   \n",
      "10       4   0    5     0     0     0     0     0     0     0  ...    0    0   \n",
      "100      0   0    0     0     0     0     0     0     0     0  ...    3    0   \n",
      "101      3   0    0     0     0     0     0     0     0     0  ...    0    0   \n",
      "102      0   0    0     0     0     0     0     0     0     0  ...    0    0   \n",
      "\n",
      "movieId  992  993  994  995  996  997  998  999  \n",
      "userId                                           \n",
      "1          0    0    0    0    0    0    0    0  \n",
      "10         0    0    0    0    0    0    0    0  \n",
      "100        0    0    0    0    0    0    0    0  \n",
      "101        0    0    0    0    0    0    0    0  \n",
      "102        0    2    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 1663 columns]\n",
      "TEST\n",
      "(878, 1253)\n",
      "movieId  1  10  100  1001  1003  1005  1006  1007  1008  1009  ...  99  990  \\\n",
      "userId                                                         ...            \n",
      "1        0   0    0     0     0     0     0     0     0     0  ...   0    0   \n",
      "10       0   0    0     0     0     0     0     0     0     0  ...   0    0   \n",
      "100      0   0    0     0     0     0     0     0     0     0  ...   0    0   \n",
      "101      0   0    0     0     0     0     0     0     0     0  ...   0    0   \n",
      "102      3   0    0     0     0     0     0     0     0     0  ...   0    0   \n",
      "\n",
      "movieId  991  992  993  994  995  997  998  999  \n",
      "userId                                           \n",
      "1          0    0    0    0    0    0    0    0  \n",
      "10         0    0    0    0    0    0    0    0  \n",
      "100        0    0    0    0    0    0    0    0  \n",
      "101        0    0    0    0    0    0    0    0  \n",
      "102        0    0    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 1253 columns]\n"
     ]
    }
   ],
   "source": [
    "def create_train_test(data, t):\n",
    "    training_df = data.iloc[0:int(data.shape[0]*t)]    \n",
    "    validation_df = data.iloc[int(data.shape[0]*t):]    \n",
    "    return training_df, validation_df\n",
    "\n",
    "names = ['userId', 'movieId', 'rating', 'timestamp']\n",
    "data = pd.read_csv('ml-100k/u.data', '\\t', names=names,\n",
    "                       engine='python')\n",
    "# https://medium.com/@gazzaazhari/model-based-collaborative-filtering-systems-with-machine-learning-algorithm-d5994ae0f53b\n",
    "columns = ['item_id', 'movie title', 'release date', 'video release date', 'IMDb URL', 'unknown', 'Action', 'Adventure',\n",
    "          'Animation', 'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror',\n",
    "          'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "movies = pd.read_csv('ml-100k/u.item', sep='|', names=columns, encoding='latin-1')\n",
    "movie_names = movies[['item_id', 'movie title']]\n",
    "movie_names.head()\n",
    "\n",
    "\n",
    "\n",
    "data['userId'] = data['userId'].astype('str')\n",
    "data['movieId'] = data['movieId'].astype('str')\n",
    "users = data['userId'].unique() \n",
    "movies = data['movieId'].unique() \n",
    "\n",
    "print(data.shape[0]*0.9)\n",
    "training_df, validation_df = create_train_test(data,0.9)\n",
    "print(data.shape)\n",
    "print(training_df.shape)\n",
    "print(validation_df.shape)\n",
    "\n",
    "print(\"Total Unique Users\", len(users))\n",
    "# should be 943\n",
    "print(\"Total Unique Movies\", len(movies))\n",
    "# should be 1682\n",
    "print(data.head())\n",
    "data = training_df.pivot_table(index='userId', columns='movieId', values='rating',fill_value=0)\n",
    "# https://predictivehacks.com/item-based-collaborative-filtering-in-python/\n",
    "data2 = validation_df.pivot_table(index='userId', columns='movieId', values='rating',fill_value=0)\n",
    "print(\"TRAIN\")\n",
    "print(data.shape)\n",
    "print(data.head())\n",
    "print(\"TEST\")\n",
    "print(data2.shape)\n",
    "print(data2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 943)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Item based filtering\n",
    "X = data.T\n",
    "# user based filtering\n",
    "# X = data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 12)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://medium.com/@gazzaazhari/model-based-collaborative-filtering-systems-with-machine-learning-algorithm-d5994ae0f53b\n",
    "SVD = TruncatedSVD(n_components=12, random_state=5)\n",
    "resultant_matrix = SVD.fit_transform(X)\n",
    "resultant_matrix.shape\n",
    "# print(resultant_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 1682)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_mat = np.corrcoef(resultant_matrix)\n",
    "corr_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', 'Get Shorty (1995)', 'Copycat (1995)', 'Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)', 'Twelve Monkeys (1995)', 'Babe (1995)', 'Dead Man Walking (1995)', 'Richard III (1995)', 'Seven (Se7en) (1995)', 'Usual Suspects, The (1995)', 'Mighty Aphrodite (1995)', 'Postino, Il (1994)', \"Mr. Holland's Opus (1995)\", 'French Twist (Gazon maudit) (1995)', 'From Dusk Till Dawn (1996)', 'White Balloon, The (1995)', \"Antonia's Line (1995)\", 'Angels and Insects (1995)']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "movies_list =list(movie_names['movie title'])\n",
    "print(movies_list[:20])\n",
    "toy_story = movies_list.index('Toy Story (1995)')\n",
    "print(toy_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1682\n",
      "1682\n",
      "0.9999999999999998\n",
      "['Toy Story (1995)', 'GoldenEye (1995)', 'Four Rooms (1995)', 'Get Shorty (1995)', 'Copycat (1995)', 'Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)', 'Twelve Monkeys (1995)', 'Babe (1995)', 'Dead Man Walking (1995)', 'Richard III (1995)', 'Seven (Se7en) (1995)', 'Usual Suspects, The (1995)', 'Mighty Aphrodite (1995)', 'Postino, Il (1994)', \"Mr. Holland's Opus (1995)\", 'French Twist (Gazon maudit) (1995)', 'From Dusk Till Dawn (1996)', 'White Balloon, The (1995)', \"Antonia's Line (1995)\", 'Angels and Insects (1995)']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RECOMMENDED LIST HERE\n",
      "['Toy Story (1995)', 'Amadeus (1984)', 'Citizen Ruth (1996)', 'Wolf (1994)', 'Something to Talk About (1995)', 'Mrs. Winterbourne (1996)', 'Last Man Standing (1996)', 'Bad Taste (1987)', \"April Fool's Day (1986)\", 'Mrs. Dalloway (1997)', 'Chungking Express (1994)']\n"
     ]
    }
   ],
   "source": [
    "corr_toy_story = corr_mat[toy_story]\n",
    "print(len(corr_toy_story))\n",
    "print(len(movies_list))\n",
    "print(corr_toy_story[0])\n",
    "print(movies_list[:20])\n",
    "mList = []\n",
    "for i in range(len(movies_list)):\n",
    "    if ((corr_toy_story[i]<1.0) & (corr_toy_story[i]>0.9)):\n",
    "        mList.append(movies_list[i])\n",
    "# list(movies_list[(corr_toy_story<1.0) & (corr_toy_story > 0.95)])\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "print(\"RECOMMENDED LIST HERE\")\n",
    "print(mList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED\n",
      "[[2.12004072 2.55897857 2.82557894 ... 1.79760591 1.57904582 2.0744154 ]\n",
      " [1.46763223 1.56292607 1.73006782 ... 1.27836313 1.04614455 0.99559578]\n",
      " [2.40785835 2.51195133 2.47636523 ... 2.58190663 2.08716489 2.70484126]\n",
      " ...\n",
      " [1.94214976 2.35111712 2.15515117 ... 1.76963405 1.82714526 2.20542185]\n",
      " [2.37155757 2.43241685 2.45316945 ... 1.80696045 1.63966072 2.29429626]\n",
      " [1.80545034 2.03450804 1.79587103 ... 1.40638195 1.632797   2.24262222]]\n",
      "DATA\n",
      "[[5 3 5 ... 0 0 0]\n",
      " [4 0 5 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [4 0 2 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [4 0 5 ... 0 0 0]]\n",
      "DELTA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-92-238dd76dddcb>:29: RuntimeWarning: overflow encountered in double_scalars\n",
      "  sse_accum += diff**2 #keep tracking the sum of square error for the matrix\n",
      "<ipython-input-92-238dd76dddcb>:35: RuntimeWarning: overflow encountered in double_scalars\n",
      "  q[k, j] += learning_rate * (2*diff*p[i, k])\n",
      "<ipython-input-92-238dd76dddcb>:34: RuntimeWarning: overflow encountered in double_scalars\n",
      "  p[i, k] += learning_rate * (2*diff*q[k, j])\n",
      "<ipython-input-92-238dd76dddcb>:34: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  p[i, k] += learning_rate * (2*diff*q[k, j])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for epoch 1\n",
      "nan\n",
      "RMSE for epoch 2\n",
      "nan\n",
      "RMSE for epoch 3\n",
      "nan\n",
      "RMSE for epoch 4\n",
      "nan\n",
      "RMSE for epoch 5\n",
      "nan\n",
      "RMSE for epoch 6\n",
      "nan\n",
      "RMSE for epoch 7\n",
      "nan\n",
      "RMSE for epoch 8\n",
      "nan\n",
      "RMSE for epoch 9\n",
      "nan\n",
      "RMSE for epoch 10\n",
      "nan\n",
      "RMSE for epoch 11\n",
      "nan\n",
      "RMSE for epoch 12\n",
      "nan\n",
      "RMSE for epoch 13\n",
      "nan\n",
      "RMSE for epoch 14\n",
      "nan\n",
      "RMSE for epoch 15\n",
      "nan\n",
      "RMSE for epoch 16\n",
      "nan\n",
      "RMSE for epoch 17\n",
      "nan\n",
      "RMSE for epoch 18\n",
      "nan\n",
      "RMSE for epoch 19\n",
      "nan\n",
      "RMSE for epoch 20\n",
      "nan\n",
      "RMSE for epoch 21\n",
      "nan\n",
      "RMSE for epoch 22\n",
      "nan\n",
      "RMSE for epoch 23\n",
      "nan\n",
      "RMSE for epoch 24\n",
      "nan\n",
      "RMSE for epoch 25\n",
      "nan\n",
      "RMSE for epoch 26\n",
      "nan\n",
      "RMSE for epoch 27\n",
      "nan\n",
      "RMSE for epoch 28\n",
      "nan\n",
      "RMSE for epoch 29\n",
      "nan\n",
      "RMSE for epoch 30\n",
      "nan\n",
      "RMSE for epoch 31\n",
      "nan\n",
      "RMSE for epoch 32\n",
      "nan\n",
      "RMSE for epoch 33\n",
      "nan\n",
      "RMSE for epoch 34\n",
      "nan\n",
      "RMSE for epoch 35\n",
      "nan\n",
      "RMSE for epoch 36\n",
      "nan\n",
      "RMSE for epoch 37\n",
      "nan\n",
      "RMSE for epoch 38\n",
      "nan\n",
      "RMSE for epoch 39\n",
      "nan\n",
      "RMSE for epoch 40\n",
      "nan\n",
      "RMSE for epoch 41\n",
      "nan\n",
      "RMSE for epoch 42\n",
      "nan\n",
      "RMSE for epoch 43\n",
      "nan\n",
      "RMSE for epoch 44\n",
      "nan\n",
      "RMSE for epoch 45\n",
      "nan\n",
      "RMSE for epoch 46\n",
      "nan\n",
      "RMSE for epoch 47\n",
      "nan\n",
      "RMSE for epoch 48\n",
      "nan\n",
      "RMSE for epoch 49\n",
      "nan\n",
      "RMSE for epoch 50\n",
      "nan\n",
      "[[nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " ...\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]\n",
      " [nan nan nan ... nan nan nan]]\n"
     ]
    }
   ],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "def SVD(learning_rate=0.2,latent_features=6, epochs = 50):\n",
    "\n",
    "    p = np.random.uniform(0,1.1,size=(data.shape[0],latent_features))\n",
    "    q = np.random.uniform(0,1.1,size=(latent_features, data.shape[1]))\n",
    "\n",
    "    \n",
    "# print(p)\n",
    "# print(q)\n",
    "    sse_accum = 0\n",
    "    pred = p.dot(q)\n",
    "    print(\"PRED\")\n",
    "    print(pred)\n",
    "    print(\"DATA\")\n",
    "    print(data)\n",
    "    print(\"DELTA\")\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(data.shape[0]):\n",
    "            for j in range(data.shape[1]):\n",
    "                sse_accum = 0\n",
    "#                 unsure if this is necessary\n",
    "        # if the rating exists\n",
    "        \n",
    "#             print(data[i,j])\n",
    "                if data[i, j] > 0:\n",
    "#          verified by debugger and annie wangliu\n",
    "                    diff = data[i, j] - np.dot(p[i, :], q[:, j])\n",
    "                    sse_accum += diff**2 #keep tracking the sum of square error for the matrix\n",
    "                    for k in range(latent_features):\n",
    "#                         update is\n",
    "#                         verified by wiki, annie wangliu;\n",
    "#                         verified by debugger\n",
    "                        p[i, k] += learning_rate * (2*diff*q[k, j])\n",
    "                        q[k, j] += learning_rate * (2*diff*p[i, k])\n",
    "        learning_rate*=.95\n",
    "        print(\"RMSE for epoch \"+str(epoch+1))\n",
    "        print(rmse(p.dot(q),data))\n",
    "    return(p,q)\n",
    "\n",
    "p,q=SVD()\n",
    "# print(\"RMSE: \")\n",
    "print(p.dot(q)-data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
